# Python ZINB Graphical Model Dockerfile (UV-based)
# Multi-stage build: base -> deps -> runtime
#
# CPU-in-CI, CUDA-at-container-start:
# - GitHub Actions runners frequently run out of disk if you bake CUDA torch wheels
#   into the image.
# - This Dockerfile therefore installs CPU-only torch by default (small), and the
#   final image includes an entrypoint that detects NVIDIA GPUs and upgrades torch
#   to CUDA wheels when the container is started on a GPU machine.
# - To disable the auto-upgrade, set PREGRAPHMODELING_TORCH_AUTO=0.
#
# Notes on GPU:
# - CUDA-enabled PyTorch wheels bundle CUDA runtime libraries, but still require a
#   compatible NVIDIA driver on the host and Docker run with GPU access.
# - Typical run: `docker run --gpus all ...`

ARG DEPS_IMAGE=deps
ARG BASE_IMAGE=python:3.11-slim

# ============================================================================
# Stage 1: Base - System dependencies
# ============================================================================
FROM ${BASE_IMAGE} AS base

ARG DEBIAN_FRONTEND=noninteractive
ARG SKIP_BASE_DEPS=false

# Install system dependencies for PyTorch and scientific computing
RUN if [ "$SKIP_BASE_DEPS" = "false" ]; then \
    apt-get update && apt-get install -y \
        build-essential \
        bash \
        git \
        curl \
        wget \
        ca-certificates \
        libgomp1 \
        && rm -rf /var/lib/apt/lists/*; \
    else \
        echo "Skipping base dependency installation (using pre-built base image)"; \
    fi

# Install UV into the image (system-wide)
# - Uses Astral's official installer.
# - Pinning UV_VERSION is optional; leave blank to get the latest.
ARG UV_VERSION=
ENV UV_INSTALL_DIR=/usr/local/bin
RUN curl -LsSf https://astral.sh/uv/install.sh | sh

# ============================================================================
# Stage 2: Deps - Python packages with PyTorch
# ============================================================================
FROM base AS deps

ARG DEBIAN_FRONTEND=noninteractive

WORKDIR /app

# Configure which PyTorch wheel index to use during the image build.
# Default is CPU-only to keep CI images small.
# Common values:
#   - CPU:       https://download.pytorch.org/whl/cpu
#   - CUDA 11.8: https://download.pytorch.org/whl/cu118
#   - CUDA 12.1: https://download.pytorch.org/whl/cu121   (common for A100/RTX 30)
#   - CUDA 12.4: https://download.pytorch.org/whl/cu124
ARG UV_INDEX_URL=https://download.pytorch.org/whl/cpu
ARG UV_EXTRA_INDEX_URL=https://pypi.org/simple
ARG UV_INDEX_STRATEGY=unsafe-best-match

# Copy only dependency files first for better Docker layer caching
COPY python/pyproject.toml /app/pyproject.toml
COPY python/requirements.txt /app/requirements.txt

# Install runtime + dev deps into the system interpreter using uv
RUN uv pip install --system \
      --index-url ${UV_INDEX_URL} \
      --extra-index-url ${UV_EXTRA_INDEX_URL} \
      --index-strategy ${UV_INDEX_STRATEGY} \
      -r /app/requirements.txt && \
    uv pip install --system \
      --index-url ${UV_INDEX_URL} \
      --extra-index-url ${UV_EXTRA_INDEX_URL} \
      --index-strategy ${UV_INDEX_STRATEGY} \
      pytest>=7.0.0 pytest-cov>=4.0.0

# ============================================================================
# Stage 3: Runtime - Application code
# ============================================================================
FROM ${DEPS_IMAGE} AS runtime

ARG DEBIAN_FRONTEND=noninteractive

WORKDIR /app

# Entry point that upgrades torch to CUDA wheels on GPU machines.
# Defaults to cu121 at runtime; override per host driver/GPU as needed.
# (A100 often works with cu121 or cu118.)
ENV PREGRAPHMODELING_TORCH_AUTO=1
ENV PREGRAPHMODELING_TORCH_GPU_INDEX_URL=https://download.pytorch.org/whl/cu121
ENV PREGRAPHMODELING_UV_INDEX_STRATEGY=unsafe-best-match
ENV PREGRAPHMODELING_TORCH_GPU_PACKAGES="torch torchvision torchaudio"

# Copy Python module
COPY python/ /app/

# Copy entrypoint script
COPY docker/uv_torch_autoinstall.sh /usr/local/bin/uv_torch_autoinstall
RUN chmod +x /usr/local/bin/uv_torch_autoinstall

# Ensure torch auto-install also runs when ENTRYPOINT is bypassed (e.g., exec vs run).
# Bash sources $BASH_ENV for non-interactive shells, which includes bash scripts.
COPY docker/uv_torch_autoinstall_env.sh /etc/profile.d/uv_torch_autoinstall_env.sh
RUN chmod +x /etc/profile.d/uv_torch_autoinstall_env.sh
ENV BASH_ENV=/etc/profile.d/uv_torch_autoinstall_env.sh

# Install the package (editable), without re-resolving dependencies
RUN uv pip install --system -e . --no-deps

# Set environment variables for GPU
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTHONUNBUFFERED=1

ENTRYPOINT ["/usr/local/bin/uv_torch_autoinstall"]

CMD ["python", "-m", "pytest", "tests/", "-v"]
