[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "zinb_graphical_model"
version = "0.1.1"
description = "ZINB Graphical Model with PyTorch/Pyro using pseudo-likelihood inference"
readme = "README.md"
license = {text = "GPL-3.0"}
authors = [
    {name = "GW McElfresh", email = "mcelfreshgw@gmail.com"}
]
requires-python = ">=3.9"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Bio-Informatics",
]
dependencies = [
    # NOTE on PyTorch + GPU wheels:
    # - CUDA-enabled wheels live on the PyTorch index, not PyPI.
    # - The selected wheel is controlled by the index URL (e.g. cu121/cu118/cpu) and
    #   the resolved version often includes a local version tag like "+cu121".
    # - For NVIDIA A100 (Ampere), CUDA 11.8 or 12.1 wheels are common choices, depending
    #   on your host driver. Start with cu121 if your driver supports CUDA 12.
    "torch>=2.5.1",
    "pyro-ppl>=1.8.0",
    "numpy>=1.20.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
]

[project.urls]
Homepage = "https://github.com/GWMcElfresh/PreGraphModeling"
Repository = "https://github.com/GWMcElfresh/PreGraphModeling"

[tool.setuptools.packages.find]
where = ["."]
include = ["zinb_graphical_model*"]

[tool.uv]
# UV resolution notes:
# - We prefer the PyTorch wheel index first so GPU builds (e.g. +cu121) are discoverable.
# - UV defaults to a conservative index strategy to avoid dependency confusion; since we
#   trust both PyPI and the official PyTorch index, we set unsafe-best-match.
#
# Common PyTorch wheel indices:
# - CPU only:   https://download.pytorch.org/whl/cpu
# - CUDA 11.8:  https://download.pytorch.org/whl/cu118  (common for older drivers)
# - CUDA 12.1:  https://download.pytorch.org/whl/cu121  (common for RTX 30/A100)
# - CUDA 12.4:  https://download.pytorch.org/whl/cu124  (if you need newer CUDA)
index-url = "https://download.pytorch.org/whl/cu121"
extra-index-url = ["https://pypi.org/simple"]
index-strategy = "unsafe-best-match"
